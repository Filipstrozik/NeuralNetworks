{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n",
      "63\n",
      "0\n",
      "Epoch 1/40 - Loss: 0.5244547724723816\n",
      "1\n",
      "Epoch 2/40 - Loss: 0.5824915170669556\n",
      "2\n",
      "Epoch 3/40 - Loss: 0.7102937698364258\n",
      "3\n",
      "Epoch 4/40 - Loss: 0.2919381260871887\n",
      "4\n",
      "Epoch 5/40 - Loss: 0.23958824574947357\n",
      "5\n",
      "Epoch 6/40 - Loss: 0.3880336284637451\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "#how to get train and test data\n",
    "train_data = datasets.FashionMNIST('path', download=True, train=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST('path', download=True, train=False, transform=transform)\n",
    "\n",
    "\n",
    "train_indices = list(range(len(train_data)))\n",
    "random.shuffle(train_indices)\n",
    "train_indices_10_percent = train_indices[:len(train_indices)//10]\n",
    "\n",
    "test_indices = list(range(len(test_data)))\n",
    "random.shuffle(test_indices)\n",
    "test_indices_10_percent = test_indices[:len(test_indices)//10]\n",
    "\n",
    "train_data_10_percent = Subset(train_data, train_indices_10_percent)\n",
    "test_data_10_percent = Subset(test_data, test_indices_10_percent)\n",
    "\n",
    "#Define a dataloader to load data\n",
    "train_loader = torch.utils.data.DataLoader(train_data_10_percent, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data_10_percent, batch_size=16, shuffle=True)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))    \n",
    "def train(model, criterion, optimizer, data_loader, test_loader, epochs):\n",
    "    strart_timestamp = time.time()\n",
    "    training_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        for images, labels in data_loader:\n",
    "            # Flatten images\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            # Zero out the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass, get our logits\n",
    "            logits = model(images)\n",
    "            # Calculate the loss with the logits and the labels\n",
    "            loss = criterion(logits, labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item()}\")\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                # Flatten images\n",
    "                images = images.view(images.shape[0], -1)\n",
    "                # Forward pass, get our logits\n",
    "                logits = model(images)\n",
    "                # Calculate the loss with the logits and the labels\n",
    "                loss = criterion(logits, labels)\n",
    "            test_loss.append(loss.item())\n",
    "\n",
    "    print(f\"\\nTraining Time (in minutes) = {(time.time()-strart_timestamp)/60:.2f}\")\n",
    "    print(training_loss, test_loss)\n",
    "    return training_loss, test_loss\n",
    "\n",
    "def plot_loss(losses, title):\n",
    "    train, test = losses\n",
    "    plt.plot(train)\n",
    "    plt.plot(test)\n",
    "    plt.legend(['Train', 'Test'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(0, 3)\n",
    "    plt.show()\n",
    "\n",
    "# Define the network architecture\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim = 1))\n",
    "\n",
    "def init_xavier(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "model.apply(init_xavier)\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss();\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "epochs = 40\n",
    "\n",
    "\n",
    "\n",
    "losses = train(model, criterion, optimizer, train_loader, test_loader, epochs=epochs)\n",
    "plot_loss(losses, 'Losses')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
